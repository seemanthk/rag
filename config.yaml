# RAG System Configuration for Amazon Products

# Dataset configuration
dataset:
  name: "amazon_products"
  path: "data/Amazon-Products.csv"
  cache_dir: "data/cache"

# Embedding model configuration
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  dimension: 384
  batch_size: 32
  device: "cpu"  # Using CPU due to CUDA compatibility issues

# Vector database configuration
vector_db:
  type: "faiss"  # or "chromadb"
  index_path: "data/vector_index"
  similarity_metric: "cosine"

# LLM configurations
llms:
  llama3:
    model_name: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
    quantization: null        # ⬅️ disable 4bit on CPU
    max_new_tokens: 100
    temperature: 0.7
    top_p: 0.9
    device: "cpu"             # ⬅️ force CPU

  mistral:
    model_name: "mistralai/Mistral-7B-Instruct-v0.3"
    quantization: null        # ⬅️ or remove the key
    max_new_tokens: 128
    temperature: 0.8
    top_p: 0.95
    device: "cpu"

  phi3:
    model_name: "microsoft/Phi-3-mini-4k-instruct"
    quantization: null
    max_new_tokens: 128
    temperature: 0.7
    top_p: 0.9
    device: "cpu"


# RAG configuration
rag:
  top_k: 3
  chunk_size: 512
  chunk_overlap: 50
  reranking: false

# Evaluation configuration
evaluation:
  metrics:
    - "answer_relevancy"
    - "faithfulness"
    - "context_precision"
    - "response_length"
  output_dir: "outputs"

# Generation prompts
prompts:
  system_prompt: |
    You are a helpful AI assistant specialized in answering questions about Amazon products.
    Use the provided context to answer the user's question accurately and concisely.
    If you cannot find the answer in the context, say so clearly.

  qa_template: |
    Context information is below:
    ---------------------
    {context}
    ---------------------

    Given the context information and not prior knowledge, answer the query.
    Query: {query}
    Answer:
